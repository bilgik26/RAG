{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dzNnr2-4yS8"
      },
      "source": [
        "###LLMを使った、 「吾輩は猫である」に基づいたRetrieval Augmented Generation(RAG)の実装\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vllm\n",
        "!pip install sentence_transformers\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "ud4heqf8xbYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from vllm import LLM, SamplingParams\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def load_model(model_name):\n",
        "    model = LLM(model=model_name, quantization=\"awq\", gpu_memory_utilization=0.6)\n",
        "    tokenizer = model.get_tokenizer()\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_embedding_model(embedding_model_name):\n",
        "    embedding_model = SentenceTransformer(embedding_model_name)\n",
        "    return embedding_model"
      ],
      "metadata": {
        "id": "EZKpTy582hwS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NLJA5HfSIaK6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_text(model):\n",
        "    df = pd.read_csv('RAG/neco.txt', header=None, names=['content'])\n",
        "    passages = ['passage: ' + content for content in df.content.tolist()]\n",
        "    passage_embeddings = model.encode(passages, normalize_embeddings=True)\n",
        "    return df, passages, passage_embeddings\n",
        "\n",
        "def retrieve_text(df, passages, passage_embeddings, query, model, verbose=False):\n",
        "    query_embeddings = model.encode(['query: ' + query], normalize_embeddings=True)\n",
        "    scores = (query_embeddings @ passage_embeddings.T) * 100\n",
        "\n",
        "    top_k = 3\n",
        "    top_k_idx = scores[0].argsort()[::-1][:top_k]\n",
        "\n",
        "    retrieved_text = f\"\"\"{df.content.tolist()[top_k_idx[0]][:20]}\n",
        "    {df.content.tolist()[top_k_idx[1]][:20]}\n",
        "    {df.content.tolist()[top_k_idx[2]][:20]}\n",
        "    \"\"\"\n",
        "\n",
        "    if verbose:\n",
        "        # 検索結果上位3件: cores[0][scores[0].argsort()[::-1][:3]]\n",
        "        return retrieved_text, scores\n",
        "\n",
        "    return retrieved_text, ''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_text(query, retrieved_text, is_retrieval):\n",
        "    DEFAULT_SYSTEM_PROMPT = \"あなたは誠実で優秀な日本人のアシスタントです。特に指示が無い場合は、常に日本語で回答してください。\"\n",
        "\n",
        "    if is_retrieval:\n",
        "        text = f\"\"\"{retrieved_text}\n",
        "        上記の文章のみをもとにして質問に回答してください。一歩ずつ考えましょう。\n",
        "        質問: {query}\n",
        "        回答:\"\"\"\n",
        "    else:\n",
        "        text=f\"\"\"質問: {query}\n",
        "        回答:\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": text},\n",
        "    ]\n",
        "\n",
        "    return messages"
      ],
      "metadata": {
        "id": "4CAWQXPM3qkN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, messages):\n",
        "    sampling_params = SamplingParams(temperature=0.6, top_p=0.9, max_tokens=1000)\n",
        "    prompt = [tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )]\n",
        "\n",
        "    output = model.generate(prompt, sampling_params)\n",
        "\n",
        "    return output[0].outputs[0].text"
      ],
      "metadata": {
        "id": "_XV8rNeGqA1V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'elyza/Llama-3-ELYZA-JP-8B-AWQ'  # https://huggingface.co/elyza/Llama-3-ELYZA-JP-8B\n",
        "embedding_model_name = 'intfloat/multilingual-e5-large'  # https://huggingface.co/intfloat/multilingual-e5-large\n",
        "\n",
        "model, tokenizer = load_model(model_name)\n",
        "embedding_model = load_embedding_model(embedding_model_name)\n",
        "df, passages, passage_embeddings = load_text(embedding_model)\n",
        "\n",
        "is_retrieval = True\n",
        "verbose = True\n",
        "\n",
        "def rag(query, is_retrieval):\n",
        "    if is_retrieval:\n",
        "        retrieved_text, scores = retrieve_text(df, passages, passage_embeddings, query, embedding_model, verbose)\n",
        "    else:\n",
        "        retrieved_text = None\n",
        "\n",
        "    messages = format_text(query, retrieved_text, is_retrieval)\n",
        "    output = generate_text(model, tokenizer, messages)\n",
        "    return output, scores"
      ],
      "metadata": {
        "id": "uzSnl_K90kMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output, scores = rag(\"吾輩が指すものは何ですか。\", is_retrieval)"
      ],
      "metadata": {
        "id": "0WpOrh6gZPIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 検索結果上位3件\n",
        "print('score: ', scores[0][scores[0].argsort()[::-1][0]])\n",
        "print(passages[scores[0].argsort()[::-1][0]])\n",
        "print('score: ', scores[0][scores[0].argsort()[::-1][1]])\n",
        "print(passages[scores[0].argsort()[::-1][1]])\n",
        "print('score: ', scores[0][scores[0].argsort()[::-1][2]])\n",
        "print(passages[scores[0].argsort()[::-1][2]])"
      ],
      "metadata": {
        "id": "tCtZ93KzZ1G6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbb3c07-f5a0-40b5-d7aa-5b45cad7c622"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score:  86.883286\n",
            "passage: 吾輩（わがはい）は猫である。名前はまだ無い。\n",
            "score:  85.5455\n",
            "passage: 吾輩はまた少々休養を要する。主人と多々良君が上野公園でどんな真似をして、芋坂で団子を幾皿食ったかその辺の逸事は探偵の必要もなし、また尾行（びこう）する勇気もないからずっと略してその間（あいだ）休養せんければならん。休養は万物の旻天（びんてん）から要求してしかるべき権利である。この世に生息すべき義務を有して蠢動（しゅんどう）する者は、生息の義務を果すために休養を得ねばならぬ。もし神ありて汝（なんじ）は働くために生れたり寝るために生れたるに非ずと云わば吾輩はこれに答えて云わん、吾輩は仰せのごとく働くために生れたり故に働くために休養を乞うと。主人のごとく器械に不平を吹き込んだまでの木強漢（ぼくきょうかん）ですら、時々は日曜以外に自弁休養をやるではないか。多感多恨にして日夜心神を労する吾輩ごとき者は仮令（たとい）猫といえども主人以上に休養を要するは勿論の事である。ただ先刻（さっき）多々良君が吾輩を目して休養以外に何等の能もない贅物（ぜいぶつ）のごとくに罵（ののし）ったのは少々気掛りである。とかく物象（ぶっしょう）にのみ使役せらるる俗人は、五感の刺激以外に何等の活動もないので、他を評価するのでも形骸以外に渉（わた）らんのは厄介である。何でも尻でも端折（はしょ）って、汗でも出さないと働らいていないように考えている。達磨（だるま）と云う坊さんは足の腐るまで座禅をして澄ましていたと云うが、仮令（たとい）壁の隙（すき）から蔦（つた）が這い込んで大師の眼口を塞（ふさ）ぐまで動かないにしろ、寝ているんでも死んでいるんでもない。頭の中は常に活動して、廓然無聖（かくねんむしょう）などと乙な理窟を考え込んでいる。儒家にも静坐の工夫と云うのがあるそうだ。これだって一室の中（うち）に閉居して安閑と躄（いざり）の修行をするのではない。脳中の活力は人一倍熾（さかん）に燃えている。ただ外見上は至極沈静端粛の態（てい）であるから、天下の凡眼はこれらの知識巨匠をもって昏睡仮死（こんすいかし）の庸人（ようじん）と見做（みな）して無用の長物とか穀潰（ごくつぶ）しとか入らざる誹謗（ひぼう）の声を立てるのである。これらの凡眼は皆形を見て心を見ざる不具なる視覚を有して生れついた者で、――しかも彼（か）の多々良三平君のごときは形を見て心を見ざる第一流の人物であるから、この三平君が吾輩を目して乾屎<img src=\"../../../gaiji/1-86/1-86-15.png\" alt=\"※(「木＋厥」、第3水準1-86-15)\" class=\"gaiji\" />（かんしけつ）同等に心得るのももっともだが、恨むらくは少しく古今の書籍を読んで、やや事物の真相を解し得たる主人までが、浅薄なる三平君に一も二もなく同意して、猫鍋（ねこなべ）に故障を挟（さしはさ）む景色（けしき）のない事である。しかし一歩退いて考えて見ると、かくまでに彼等が吾輩を軽蔑（けいべつ）するのも、あながち無理ではない。大声は俚耳（りじ）に入らず、陽春白雪の詩には和するもの少なしの喩（たとえ）も古い昔からある事だ。形体以外の活動を見る能（あた）わざる者に向って己霊（これい）の光輝を見よと強（し）ゆるは、坊主に髪を結（い）えと逼（せま）るがごとく、鮪（まぐろ）に演説をして見ろと云うがごとく、電鉄に脱線を要求するがごとく、主人に辞職を勧告するごとく、三平に金の事を考えるなと云うがごときものである。必竟（ひっきょう）無理な注文に過ぎん。しかしながら猫といえども社会的動物である。社会的動物である以上はいかに高く自（みずか）ら標置するとも、或る程度までは社会と調和して行かねばならん。主人や細君や乃至（ないし）御（お）さん、三平連（づれ）が吾輩を吾輩相当に評価してくれんのは残念ながら致し方がないとして、不明の結果皮を剥（は）いで三味線屋に売り飛ばし、肉を刻んで多々良君の膳に上（のぼ）すような無分別をやられては由々（ゆゆ）しき大事である。吾輩は頭をもって活動すべき天命を受けてこの娑婆（しゃば）に出現したほどの古今来（ここんらい）の猫であれば、非常に大事な身体である。千金の子（し）は堂陲（どうすい）に坐せずとの諺（ことわざ）もある事なれば、好んで超邁（ちょうまい）を宗（そう）として、徒（いたず）らに吾身の危険を求むるのは単に自己の災（わざわい）なるのみならず、また大いに天意に背（そむ）く訳である。猛虎も動物園に入れば糞豚（ふんとん）の隣りに居を占め、鴻雁（こうがん）も鳥屋に生擒（いけど）らるれば雛鶏（すうけい）と俎（まないた）を同（おな）じゅうす。庸人（ようじん）と相互（あいご）する以上は下（くだ）って庸猫（ようびょう）と化せざるべからず。庸猫たらんとすれば鼠を捕（と）らざるべからず。――吾輩はとうとう鼠をとる事に極（き）めた。\n",
            "score:  85.53673\n",
            "passage: 吾輩は猫である。猫の癖にどうして主人の心中をかく精密に記述し得るかと疑うものがあるかも知れんが、このくらいな事は猫にとって何でもない。吾輩はこれで読心術を心得ている。いつ心得たなんて、そんな余計な事は聞かんでもいい。ともかくも心得ている。人間の膝（ひざ）の上へ乗って眠っているうちに、吾輩は吾輩の柔かな毛衣（けごろも）をそっと人間の腹にこすり付ける。すると一道の電気が起って彼の腹の中のいきさつが手にとるように吾輩の心眼に映ずる。せんだってなどは主人がやさしく吾輩の頭を撫（な）で廻しながら、突然この猫の皮を剥（は）いでちゃんちゃんにしたらさぞあたたかでよかろうと飛んでもない了見（りょうけん）をむらむらと起したのを即座に気取（けど）って覚えずひやっとした事さえある。怖（こわ）い事だ。当夜主人の頭のなかに起った以上の思想もそんな訳合（わけあい）で幸（さいわい）にも諸君にご報道する事が出来るように相成ったのは吾輩の大（おおい）に栄誉とするところである。但（ただ）し主人は「何が何だか分らなくなった」まで考えてそのあとはぐうぐう寝てしまったのである、あすになれば何をどこまで考えたかまるで忘れてしまうに違ない。向後（こうご）もし主人が気狂（きちがい）について考える事があるとすれば、もう一返（ぺん）出直して頭から考え始めなければならぬ。そうすると果してこんな径路（けいろ）を取って、こんな風に「何が何だか分らなくなる」かどうだか保証出来ない。しかし何返考え直しても、何条（なんじょう）の径路をとって進もうとも、ついに「何が何だか分らなくなる」だけはたしかである。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 回答\n",
        "print(output)"
      ],
      "metadata": {
        "id": "chy9ZNx-diE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d643e0a-9577-4597-b1d4-74444eb3e917"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "この短い文章から考えるに、吾輩が指すものは「猫」です。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def handle_submit(query, chat_history):\n",
        "    bot_message, score = rag(query, True)\n",
        "    chat_history.append((query, bot_message))\n",
        "    return \"\", chat_history\n",
        "\n",
        "js = \"\"\"\n",
        "function createGradioAnimation() {\n",
        "    var container = document.createElement('div');\n",
        "    container.id = 'gradio-animation';\n",
        "    container.style.fontSize = '2em';\n",
        "    container.style.fontWeight = 'bold';\n",
        "    container.style.textAlign = 'center';\n",
        "    container.style.marginBottom = '20px';\n",
        "\n",
        "    var text = 'Welcome';\n",
        "    for (var i = 0; i < text.length; i++) {\n",
        "        (function(i){\n",
        "            setTimeout(function(){\n",
        "                var letter = document.createElement('span');\n",
        "                letter.style.opacity = '0';\n",
        "                letter.style.transition = 'opacity 0.5s';\n",
        "                letter.innerText = text[i];\n",
        "\n",
        "                container.appendChild(letter);\n",
        "\n",
        "                setTimeout(function() {\n",
        "                    letter.style.opacity = '1';\n",
        "                }, 50);\n",
        "            }, i * 250);\n",
        "        })(i);\n",
        "    }\n",
        "\n",
        "    var gradioContainer = document.querySelector('.gradio-container');\n",
        "    gradioContainer.insertBefore(container, gradioContainer.firstChild);\n",
        "\n",
        "    return 'Animation created';\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(theme=\"Ajaxon6255/Emerald_Isle\", js=js) as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "    msg.submit(handle_submit, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "8Qa048qJAeTV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "b056f8fa-7796-480c-d365-6dcab27fec23"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://0c184e2a7bdeae0a83.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0c184e2a7bdeae0a83.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##参考文献\n",
        "In-Context Retrieval-Augmented Language Models: https://arxiv.org/abs/2302.00083"
      ],
      "metadata": {
        "id": "iMZEUsaFVx-S"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}